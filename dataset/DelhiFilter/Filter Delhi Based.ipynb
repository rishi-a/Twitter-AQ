{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob('/home/patel_zeel/AirQualityTweets/Final Dataset/20*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/patel_zeel/AirQualityTweets/Final Dataset/2017_Final.csv\n",
      "/home/patel_zeel/AirQualityTweets/Final Dataset/2020_Final.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patel_zeel/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/patel_zeel/AirQualityTweets/Final Dataset/2019_Final.csv\n",
      "/home/patel_zeel/AirQualityTweets/Final Dataset/2016_Final.csv\n",
      "/home/patel_zeel/AirQualityTweets/Final Dataset/2018_Final.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for fname in fnames:\n",
    "    print(fname)\n",
    "    df = df.append(pd.read_csv(fname, dtype=str)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"delhiagainstpollution\",\n",
    "           \"delhi against pollution\",\n",
    "           \"delhipollution\",\n",
    "           \"delhi pollution\",\n",
    "           \"smogtower\",\n",
    "           \"smog tower\",\n",
    "           \"delhi air\",\n",
    "           \"delhiair\",\n",
    "           \"delhi air emergency\",\n",
    "           \"delhiairemergency\",\n",
    "           \"delhichokes\",\n",
    "           \"delhi chokes\",\n",
    "           \"delhi air quality\",\n",
    "           \"delhiairquality\",\n",
    "           \"delhi smog\",\n",
    "           \"delhismog\",\n",
    "           \"oddeven\",\n",
    "           \"odd even\",\n",
    "           \"delhi fog\",\n",
    "           \"delhifog\",\n",
    "           \"lodhi garden\",\n",
    "           \"sarojini nagar\",\n",
    "           \"chandni chowk\",\n",
    "           \"gurgaon\",\n",
    "           \"delhincr\",\n",
    "           \"air ncr\",\n",
    "           \"air noida\",\n",
    "           \"stubble burning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(?is)^(?=.*\\\\b(delhiagainstpollution)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(against)\\\\b)(?=.*\\\\b(pollution)\\\\b).*', '(?is)^(?=.*\\\\b(delhipollution)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(pollution)\\\\b).*', '(?is)^(?=.*\\\\b(smogtower)\\\\b).*', '(?is)^(?=.*\\\\b(smog)\\\\b)(?=.*\\\\b(tower)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(air)\\\\b).*', '(?is)^(?=.*\\\\b(delhiair)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(air)\\\\b)(?=.*\\\\b(emergency)\\\\b).*', '(?is)^(?=.*\\\\b(delhiairemergency)\\\\b).*', '(?is)^(?=.*\\\\b(delhichokes)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(chokes)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(air)\\\\b)(?=.*\\\\b(quality)\\\\b).*', '(?is)^(?=.*\\\\b(delhiairquality)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(smog)\\\\b).*', '(?is)^(?=.*\\\\b(delhismog)\\\\b).*', '(?is)^(?=.*\\\\b(oddeven)\\\\b).*', '(?is)^(?=.*\\\\b(odd)\\\\b)(?=.*\\\\b(even)\\\\b).*', '(?is)^(?=.*\\\\b(delhi)\\\\b)(?=.*\\\\b(fog)\\\\b).*', '(?is)^(?=.*\\\\b(delhifog)\\\\b).*', '(?is)^(?=.*\\\\b(lodhi)\\\\b)(?=.*\\\\b(garden)\\\\b).*', '(?is)^(?=.*\\\\b(sarojini)\\\\b)(?=.*\\\\b(nagar)\\\\b).*', '(?is)^(?=.*\\\\b(chandni)\\\\b)(?=.*\\\\b(chowk)\\\\b).*', '(?is)^(?=.*\\\\b(gurgaon)\\\\b).*', '(?is)^(?=.*\\\\b(delhincr)\\\\b).*', '(?is)^(?=.*\\\\b(air)\\\\b)(?=.*\\\\b(ncr)\\\\b).*', '(?is)^(?=.*\\\\b(air)\\\\b)(?=.*\\\\b(noida)\\\\b).*', '(?is)^(?=.*\\\\b(stubble)\\\\b)(?=.*\\\\b(burning)\\\\b).*']\n"
     ]
    }
   ],
   "source": [
    "regex_queries = ['(?is)^'+''.join(['(?=.*\\\\b('+j+')\\\\b)' for j in i.split()])+'.*' for i in queries]\n",
    "print(regex_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patel_zeel/anaconda3/lib/python3.7/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(['delhi is againstof pollution', 'delhi is against pollution']).str.contains(regex_queries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit preprocessing\n",
    "df.tweet = df.tweet.apply(lambda x: x.replace('#','# ') if x==x else x) # x==x filters NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "(?is)^(?=.*\\b(delhiagainstpollution)\\b).* Time taken is 0.8418810407320658 minutes 2078 matches\n",
      "Total time taken is 0.8418965180714925 minutes\n"
     ]
    }
   ],
   "source": [
    "init = time()\n",
    "index_set = set()\n",
    "print('starting')\n",
    "for query in regex_queries:\n",
    "    tmp = df.tweet.str.contains(query, regex=True, case=False)\n",
    "    indices = tmp.where(tmp==True).dropna().index.tolist()\n",
    "    index_set.update(set(indices))\n",
    "    print(query, 'Time taken is',(time()-init)/60, 'minutes', len(indices), 'matches')\n",
    "    ###########################\n",
    "    # Break is only for testing purpose\n",
    "    # Remove break from here to search for all queries one by one\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "print('Total time taken is',(time()-init)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of filtered queries is 2078\n"
     ]
    }
   ],
   "source": [
    "print('Total length of filtered queries is',len(index_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_df = df.loc[list(index_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_df.to_csv('delhi-filtered.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
