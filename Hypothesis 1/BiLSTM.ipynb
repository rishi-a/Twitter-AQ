{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishi-a/Twitter-AQ/blob/master/Hypothesis%201/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MK9UnTPliyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm\n",
        "import pickle \n",
        "#pd.set_option('display.max_colwidth', 2000) # To visualize full output\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raEH3lN6lqi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle \n",
        "#dum = pd.read_csv('https://raw.githubusercontent.com/patel-zeel/kdd_data_open/master/smogtowertweets%2B150.csv')\n",
        "#url = 'https://raw.githubusercontent.com/patel-zeel/kdd_data_open/master/SmogTweet500%20-%20210TZ.csv'\n",
        "df_main = pd.read_csv('OddEven.csv')\n",
        "#frames = [df_main,dum]\n",
        "#df_main = pd.concat(frames)\n",
        "#df_main = df_main.loc[df_main['TLabel'] == df_main['ZLabel']]\n",
        "df_main.shape\n",
        "#df_main = df_main.sample(len(df_main), random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNUJ5MXrluNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(tweet):\n",
        "  #tweet = tweet.replace('@ ','@').replace('# ','#')\n",
        "  return ' '.join(w for w in tweet.split() if w[0] not in ['@'] and \n",
        "                  not w.startswith('pic.twitter.com') and\n",
        "                  not w.startswith('http://') and\n",
        "                  not w.startswith('https://')).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frPmGf7_lwUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df_main\n",
        "df['Tweet text processed'] = df['tweet'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bYXvrCCTcb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('before',len(df))\n",
        "df = df.drop_duplicates(subset='Tweet text processed')\n",
        "print('after',len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ_YimQgl0Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = df['ZLabel'].value_counts().plot(kind='bar')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbg77AEl3TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reset_index(drop = True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaNg0z3El62P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU \n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "toc = Tokenizer()\n",
        "toc.fit_on_texts(df['Tweet text processed'])\n",
        "\n",
        "max_len = max(len(s.split()) for s in df['Tweet text processed'])\n",
        "\n",
        "vocab_size = len(toc.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt-rPtGSl9xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def create_model(embedding_dim, neurons):\n",
        "\t# create model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "  model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "  model.add((Bidirectional(LSTM(neurons))))\n",
        "  #model.add(Dense(64, activation='relu'))\n",
        "  #model.add(Dense(3, activation='relu'))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "def GridSearchCV(X, y, train_val_index, y_train_val, param_grid):\n",
        "  hyperpara_dict = {}\n",
        "  kfInner = StratifiedKFold(5, shuffle=True, random_state=0)\n",
        "  train_ind, val_ind = next(kfInner.split(train_val_index, y_train_val.idxmax(axis=1).values))\n",
        "  train_df_ind = train_val_index[train_ind]\n",
        "  val_df_ind = train_val_index[val_ind]\n",
        "  X_train, y_train = X.iloc[train_df_ind], y.iloc[train_df_ind]\n",
        "  X_val, y_val = X.iloc[val_df_ind], y.iloc[val_df_ind]\n",
        "\n",
        "  train_tocs = toc.texts_to_sequences(X_train)\n",
        "  val_tocs = toc.texts_to_sequences(X_val)\n",
        "  X_train_pad = pad_sequences(train_tocs, maxlen=max_len, padding='post')\n",
        "  X_val_pad = pad_sequences(val_tocs, maxlen=max_len, padding='post')\n",
        "  \n",
        "  for embedding_dim, neurons, batch_size, epochs in product(*param_grid.values()):\n",
        "    print('searching', (embedding_dim, neurons, batch_size, epochs))\n",
        "    model = create_model(embedding_dim, neurons)\n",
        "    model.fit(X_train_pad, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "    res = model.predict(X_val_pad)\n",
        "    score = pd.DataFrame(res).max(axis =1)\n",
        "    y_pred = pd.DataFrame(res, columns=[-1,0,1]).idxmax(axis=1)\n",
        "    accuracy = f1_score(y_val.idxmax(axis=1), y_pred,average='macro')\n",
        "    hyperpara_dict.update({(embedding_dim, neurons, batch_size, epochs) : accuracy})\n",
        "  return max(hyperpara_dict, key=lambda x: hyperpara_dict[x]) # will return set of hyp having max accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Blw8SZmAiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main code\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['Tweet text processed']\n",
        "y = pd.get_dummies(df['ZLabel'])\n",
        "param_grid = {'embedding_dim':[32,64,128], \n",
        "               'neurons':[8,16,32,64], \n",
        "               'batch_size':[8,16,32], \n",
        "               'epochs' : [20, 30,50, 100]}\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "kf = StratifiedKFold()\n",
        "test_inds = []\n",
        "test_preds = []\n",
        "test_score = []\n",
        "test = []\n",
        "for train_val_index, test_index in kf.split(X, y.idxmax(axis=1)):\n",
        "  X_train_val, X_test = X.iloc[train_val_index], X.iloc[test_index]\n",
        "  y_train_val, y_test = y.iloc[train_val_index], y.iloc[test_index]\n",
        "  train_val_tocs = toc.texts_to_sequences(X_train_val)\n",
        "  test_tocs = toc.texts_to_sequences(X_test)\n",
        "  X_train_val_pad = pad_sequences(train_val_tocs, maxlen=max_len, padding='post')\n",
        "  X_test_pad = pad_sequences(test_tocs, maxlen=max_len, padding='post')\n",
        "\n",
        "  # Start Hyperpara tuning\n",
        "  embedding_dim, neurons, batch_size, epochs = GridSearchCV(X, y, train_val_index, y_train_val, param_grid)\n",
        "  print('best hyper', embedding_dim, neurons, batch_size, epochs)\n",
        "  model = create_model(embedding_dim, neurons)\n",
        "  model.fit(X_train_val_pad, y_train_val, batch_size=batch_size, epochs=epochs, verbose=0,callbacks=[LogThirdLayerOutput()])\n",
        "  res = model.predict(X_test_pad)\n",
        "  score = pd.DataFrame(res).max(axis =1)\n",
        "  y_pred = pd.DataFrame(res, columns=[-1,0,1]).idxmax(axis=1)\n",
        "  accuracy = f1_score(y_test.idxmax(axis=1), y_pred,average='macro')\n",
        "  print(accuracy)\n",
        "  test_inds.extend(test_index)\n",
        "  test_preds.extend(y_pred)\n",
        "  test_score.extend(score)\n",
        "  test.extend(y_test.idxmax(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kPtZA6kmDyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test, test_preds))\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(test_preds)\n",
        "sns.heatmap((confusion_matrix(test,test_preds)),annot=True,annot_kws={\"size\": 40},cbar=False,fmt='g',\n",
        "            xticklabels=[-1,0,1], yticklabels=[-1,0,1])\n",
        "\n",
        "plt.xlabel('predicted')\n",
        "plt.ylabel('ground truth')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wofDA2gbmHPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_inds)\n",
        "print(test)\n",
        "print(test_preds)\n",
        "print(test_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4ETL9HWmJI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reindex(test_inds)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJkrvlkrmMaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['prediction'] = test_preds\n",
        "df['score'] = test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvE5nNK7mNL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = df[['Tweet text processed','ZLabel','prediction','score']]\n",
        "result.to_csv('3bilstmwithoutoddfinal.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpAjp2GxmQ79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result[result['TLabel'] != result['prediction']]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}