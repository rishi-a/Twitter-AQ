{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEdavO8_bfm_"
      },
      "source": [
        "# SmogTower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_BqpQpKiCd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix, log_loss\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, PredefinedSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT1MhzBtIDCo"
      },
      "source": [
        "data_whole = pd.read_csv('/content/drive/My Drive/CSCW_H1/data/ST_labeled.csv')\n",
        "\n",
        "# Params\n",
        "n_folds=5\n",
        "seed=0\n",
        "ModelName = MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygESM0OBIMRA",
        "outputId": "3a1eeb18-153b-461c-81fe-6e0846ca51a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "def anyalnum(string):\n",
        "  return any(char.isalnum() for char in string)\n",
        "\n",
        "def preprocess(tweet):\n",
        "  tweet = tweet.replace('@ ','@').replace('# ','#')\n",
        "  tweet = re.sub('pic.twitter.com.*','',tweet)\n",
        "  tweet = re.sub('https*://[^\\s]+','',tweet)\n",
        "  tweet = re.sub('https*://.*','',tweet)\n",
        "  #tweet = ' '.join(word for word in tweet.split() if anyalnum(word))\n",
        "  return tweet\n",
        "\n",
        "data_whole['processed_tweet'] = data_whole['tweet'].apply(preprocess)\n",
        "data = data_whole.drop_duplicates('processed_tweet').reset_index(drop=True)\n",
        "data.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Label</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "      <th>favorites</th>\n",
              "      <th>geo</th>\n",
              "      <th>has_media</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>hour</th>\n",
              "      <th>id</th>\n",
              "      <th>img_urls</th>\n",
              "      <th>is_replied</th>\n",
              "      <th>is_reply_to</th>\n",
              "      <th>likes</th>\n",
              "      <th>link</th>\n",
              "      <th>links</th>\n",
              "      <th>mentions</th>\n",
              "      <th>name</th>\n",
              "      <th>near</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>parent_tweet_id</th>\n",
              "      <th>place</th>\n",
              "      <th>quote_url</th>\n",
              "      <th>replies</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>reply_to_users</th>\n",
              "      <th>retweet</th>\n",
              "      <th>retweet_date</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>retweets</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>search</th>\n",
              "      <th>source</th>\n",
              "      <th>text_html</th>\n",
              "      <th>timestamp_epochs</th>\n",
              "      <th>timezone</th>\n",
              "      <th>trans_dest</th>\n",
              "      <th>trans_src</th>\n",
              "      <th>translate</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_id_str</th>\n",
              "      <th>user_rt</th>\n",
              "      <th>user_rt_id</th>\n",
              "      <th>username</th>\n",
              "      <th>video_url</th>\n",
              "      <th>lang</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>India's own 'smog tower' may help combat air p...</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-11-05 12:37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.060000e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/PaperDabba/status/10593415...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PaperDabba</td>\n",
              "      <td>NaN</td>\n",
              "      <td>en</td>\n",
              "      <td>India's own 'smog tower' may help combat air p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                tweet  ...                                    processed_tweet\n",
              "43  India's own 'smog tower' may help combat air p...  ...  India's own 'smog tower' may help combat air p...\n",
              "\n",
              "[1 rows x 53 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfT-yhJaHH3Y",
        "outputId": "a8ca29d4-e1a5-48cc-c5df-bd062be58f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('number of tweets', len(data_whole))\n",
        "print('number of deduplicated tweets', len(data_whole.drop_duplicates('tweet')))\n",
        "print('number of deduplicated tweets after processing', len(data))\n",
        "data.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of tweets 516\n",
            "number of deduplicated tweets 446\n",
            "number of deduplicated tweets after processing 430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    285\n",
              "1     82\n",
              "0     63\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRUfwn0ALdaF"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english', lowercase=True)\n",
        "data_dict = {i:{'train_X':None, 'test_X':None, 'val_X':None,\n",
        "                'train_y':None, 'test_y':None, 'val_y':None} for i in range(n_folds)}\n",
        "splitter = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
        "for fold, (train_val_ind, test_ind) in enumerate(splitter.split(data.index)):\n",
        "  train_ind, val_ind = train_test_split(train_val_ind, random_state=seed, test_size=0.20)\n",
        "  data_dict[fold]['train_X'] = vectorizer.fit_transform(data.loc[train_ind]['processed_tweet'])\n",
        "  data_dict[fold]['val_X'] = vectorizer.transform(data.loc[val_ind]['processed_tweet'])\n",
        "  data_dict[fold]['test_X'] = vectorizer.transform(data.loc[test_ind]['processed_tweet'])\n",
        "  data_dict[fold]['train_y'] = data.loc[train_ind]['Label']\n",
        "  data_dict[fold]['val_y'] = data.loc[val_ind]['Label']\n",
        "  data_dict[fold]['test_y'] = data.loc[test_ind]['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5csjTofDMfds",
        "outputId": "d72ea69f-ec59-4940-ef03-74f22a0d8f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'fit_prior':(True, False), 'alpha':[0.01,0.05,0.1,0.5,1]}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ######## Hyperparameter search#########################\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].todense().tolist()+data_dict[fold]['train_X'].todense().tolist(), \n",
        "          data_dict[fold]['val_y'].to_list()+data_dict[fold]['train_y'].to_list())\n",
        "  print(clf.best_params_)\n",
        "  ######### Fit-predict with best params#################\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].values.tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 1\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 2\n",
            "{'alpha': 0.5, 'fit_prior': False}\n",
            "fold 3\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 4\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.57      0.65        63\n",
            "           1       0.51      0.46      0.49        82\n",
            "           2       0.83      0.90      0.87       285\n",
            "\n",
            "    accuracy                           0.77       430\n",
            "   macro avg       0.70      0.65      0.67       430\n",
            "weighted avg       0.76      0.77      0.76       430\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGBMA7xVbdTj"
      },
      "source": [
        "# OddEven"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzOqAW9s30S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix, log_loss\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, PredefinedSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5BcQYwds30a",
        "outputId": "2223aa07-c563-4080-8af1-0621a2050413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data_whole = pd.read_csv('/content/drive/My Drive/CSCW_H1/data/OE_labeled.csv')\n",
        "data_extra = pd.read_csv('/content/drive/My Drive/CSCW_H1/data/OE_labeled_extra.csv')\n",
        "data_whole = pd.concat([data_whole, data_extra])\n",
        "data_whole = data_whole[~data_whole['Label'].isna()].reset_index(drop=True)\n",
        "data_whole['Label'] = data_whole['Label'].astype(int)\n",
        "print(len(data_whole))\n",
        "\n",
        "# Params\n",
        "n_folds=5\n",
        "seed=0\n",
        "ModelName = MultinomialNB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NveCpb04s30f",
        "outputId": "9c6506d7-cd10-4686-b6a7-49c7523bacfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "def anyalnum(string):\n",
        "  return any(char.isalnum() for char in string)\n",
        "\n",
        "def preprocess(tweet):\n",
        "  tweet = tweet.replace('@ ','@').replace('# ','#')\n",
        "  tweet = re.sub('pic.twitter.com.*','',tweet)\n",
        "  tweet = re.sub('https*://[^\\s]+','',tweet)\n",
        "  tweet = re.sub('https*://.*','',tweet)\n",
        "  #tweet = ' '.join(word for word in tweet.split() if anyalnum(word))\n",
        "  return tweet\n",
        "\n",
        "data_whole['processed_tweet'] = data_whole['tweet'].apply(preprocess)\n",
        "data = data_whole.drop_duplicates('processed_tweet').reset_index(drop=True)\n",
        "data.sample(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>Label</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "      <th>favorites</th>\n",
              "      <th>geo</th>\n",
              "      <th>has_media</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>hour</th>\n",
              "      <th>id</th>\n",
              "      <th>img_urls</th>\n",
              "      <th>is_replied</th>\n",
              "      <th>is_reply_to</th>\n",
              "      <th>likes</th>\n",
              "      <th>link</th>\n",
              "      <th>links</th>\n",
              "      <th>mentions</th>\n",
              "      <th>name</th>\n",
              "      <th>near</th>\n",
              "      <th>nlikes</th>\n",
              "      <th>nreplies</th>\n",
              "      <th>nretweets</th>\n",
              "      <th>parent_tweet_id</th>\n",
              "      <th>place</th>\n",
              "      <th>quote_url</th>\n",
              "      <th>replies</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>reply_to_users</th>\n",
              "      <th>retweet</th>\n",
              "      <th>retweet_date</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>retweets</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>search</th>\n",
              "      <th>source</th>\n",
              "      <th>text_html</th>\n",
              "      <th>timestamp_epochs</th>\n",
              "      <th>timezone</th>\n",
              "      <th>trans_dest</th>\n",
              "      <th>trans_src</th>\n",
              "      <th>translate</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_id_str</th>\n",
              "      <th>user_rt</th>\n",
              "      <th>user_rt_id</th>\n",
              "      <th>username</th>\n",
              "      <th>video_url</th>\n",
              "      <th>lang</th>\n",
              "      <th>ZLabel</th>\n",
              "      <th>TLabel</th>\n",
              "      <th>RLabel</th>\n",
              "      <th>(1, 'ZLabel')</th>\n",
              "      <th>(148, 'ZLabel')</th>\n",
              "      <th>(7, 'TLabel')</th>\n",
              "      <th>(349, 'TLabel')</th>\n",
              "      <th>(118, 'RLabel')</th>\n",
              "      <th>(665, 'RLabel')</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>corrected_id</th>\n",
              "      <th>pred_new</th>\n",
              "      <th>pred_old</th>\n",
              "      <th>processed_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>#Delhi govt to review #OddEven first phase tod...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/SAsiaNewsline/status/68896...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.889692e+17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#Delhi govt to review #OddEven first phase tod...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweet  ...                                    processed_tweet\n",
              "800  #Delhi govt to review #OddEven first phase tod...  ...  #Delhi govt to review #OddEven first phase tod...\n",
              "\n",
              "[1 rows x 67 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odRA0xv3s30m",
        "outputId": "1a0462ee-e4a4-4693-a91d-e579798b2e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "print('number of tweets', len(data_whole))\n",
        "print('number of deduplicated tweets', len(data_whole.drop_duplicates('tweet')))\n",
        "print('number of deduplicated tweets after processing', len(data))\n",
        "data.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of tweets 1098\n",
            "number of deduplicated tweets 1096\n",
            "number of deduplicated tweets after processing 1093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    668\n",
              "2    238\n",
              "0    187\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZXVX6I1s30r"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words='english', lowercase=True)\n",
        "data_dict = {i:{'train_X':None, 'test_X':None, 'val_X':None,\n",
        "                'train_y':None, 'test_y':None, 'val_y':None} for i in range(n_folds)}\n",
        "splitter = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
        "for fold, (train_val_ind, test_ind) in enumerate(splitter.split(data.index)):\n",
        "  train_ind, val_ind = train_test_split(train_val_ind, random_state=seed, test_size=0.20)\n",
        "  data_dict[fold]['train_X'] = vectorizer.fit_transform(data.loc[train_ind]['processed_tweet'])\n",
        "  data_dict[fold]['val_X'] = vectorizer.transform(data.loc[val_ind]['processed_tweet'])\n",
        "  data_dict[fold]['test_X'] = vectorizer.transform(data.loc[test_ind]['processed_tweet'])\n",
        "  data_dict[fold]['train_y'] = data.loc[train_ind]['Label']\n",
        "  data_dict[fold]['val_y'] = data.loc[val_ind]['Label']\n",
        "  data_dict[fold]['test_y'] = data.loc[test_ind]['Label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AycGuuBs30w",
        "outputId": "841bc5c5-2616-4c58-af4f-5fd9ba92f9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'fit_prior':(True, False), 'alpha':[0.01,0.05,0.5,0.1,1]}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].todense().tolist()+data_dict[fold]['train_X'].todense().tolist(), \n",
        "          data_dict[fold]['val_y'].to_list()+data_dict[fold]['train_y'].to_list())\n",
        "  \n",
        "  print(clf.best_params_)\n",
        "\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].values.tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 1\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 2\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 3\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "fold 4\n",
            "{'alpha': 1, 'fit_prior': False}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.28      0.35       187\n",
            "           1       0.68      0.80      0.74       668\n",
            "           2       0.47      0.37      0.42       238\n",
            "\n",
            "    accuracy                           0.62      1093\n",
            "   macro avg       0.53      0.49      0.50      1093\n",
            "weighted avg       0.60      0.62      0.60      1093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfaV6GkW51Xs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}