{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classsifiers with BERT Embeds-OE.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-_BqpQpKiCd"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix, log_loss\n",
        "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, PredefinedSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEdavO8_bfm_"
      },
      "source": [
        "# OE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ8riqW2KoYV"
      },
      "source": [
        "## Common preperation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZJG86KwANA-"
      },
      "source": [
        "data_dict = pd.read_pickle('/content/drive/My Drive/CSCW_H1/data/embeds_OE_extra.pickle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMdV9PrgHavt"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSQNprvuKmn-"
      },
      "source": [
        "# params\n",
        "n_folds = 5\n",
        "ModelName = LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5csjTofDMfds",
        "outputId": "8c2a817d-0cfa-4258-8b65-89cb930cece1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'penalty':('l1','l2'), 'C':(0.01,0.1,10,100),'solver':('liblinear',),'max_iter':(1000,)}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ######## Hyperparameter search#########################\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].tolist()+data_dict[fold]['train_X'].tolist(), \n",
        "          data_dict[fold]['val_y'].tolist()+data_dict[fold]['train_y'].tolist())\n",
        "  print(clf.best_params_)\n",
        "  ######### Fit-predict with best params#################\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "fold 1\n",
            "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "fold 2\n",
            "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "fold 3\n",
            "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "fold 4\n",
            "{'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.08      0.13       187\n",
            "           1       0.65      0.96      0.78       668\n",
            "           2       0.58      0.20      0.29       238\n",
            "\n",
            "    accuracy                           0.64      1093\n",
            "   macro avg       0.55      0.41      0.40      1093\n",
            "weighted avg       0.60      0.64      0.56      1093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA0OULVKKxlU"
      },
      "source": [
        "## SVC with RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STN47q3YKxlX"
      },
      "source": [
        "# params\n",
        "n_folds = 5\n",
        "ModelName = SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nLyvitnKxlc",
        "outputId": "d90d1254-5cb2-49fa-888e-acad3ba36d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'C':(0.01,0.1,10,100),'probability':(True,)}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ######## Hyperparameter search#########################\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].tolist()+data_dict[fold]['train_X'].tolist(), \n",
        "          data_dict[fold]['val_y'].tolist()+data_dict[fold]['train_y'].tolist())\n",
        "  print(clf.best_params_)\n",
        "  ######### Fit-predict with best params#################\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'C': 0.1, 'probability': True}\n",
            "fold 1\n",
            "{'C': 0.1, 'probability': True}\n",
            "fold 2\n",
            "{'C': 0.1, 'probability': True}\n",
            "fold 3\n",
            "{'C': 10, 'probability': True}\n",
            "fold 4\n",
            "{'C': 10, 'probability': True}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.03      0.06       187\n",
            "           1       0.63      0.98      0.77       668\n",
            "           2       0.68      0.09      0.16       238\n",
            "\n",
            "    accuracy                           0.62      1093\n",
            "   macro avg       0.55      0.37      0.33      1093\n",
            "weighted avg       0.59      0.62      0.51      1093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH2u-HGCMb6k"
      },
      "source": [
        "## SVC with Polynomial kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWX9j9Z3Mb6p"
      },
      "source": [
        "# params\n",
        "n_folds = 5\n",
        "ModelName = SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLWJnFUpMb6x",
        "outputId": "faad8e1a-2f08-4634-d38e-b991229e119d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'C':(0.01,0.1,10,100),'probability':(True,),'kernel':('poly',),'degree':(3,5,7,9)}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ######## Hyperparameter search#########################\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].tolist()+data_dict[fold]['train_X'].tolist(), \n",
        "          data_dict[fold]['val_y'].tolist()+data_dict[fold]['train_y'].tolist())\n",
        "  print(clf.best_params_)\n",
        "  ######### Fit-predict with best params#################\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'C': 0.1, 'degree': 3, 'kernel': 'poly', 'probability': True}\n",
            "fold 1\n",
            "{'C': 0.1, 'degree': 3, 'kernel': 'poly', 'probability': True}\n",
            "fold 2\n",
            "{'C': 0.1, 'degree': 3, 'kernel': 'poly', 'probability': True}\n",
            "fold 3\n",
            "{'C': 10, 'degree': 7, 'kernel': 'poly', 'probability': True}\n",
            "fold 4\n",
            "{'C': 0.01, 'degree': 3, 'kernel': 'poly', 'probability': True}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.05      0.08       187\n",
            "           1       0.63      0.97      0.76       668\n",
            "           2       0.53      0.07      0.13       238\n",
            "\n",
            "    accuracy                           0.62      1093\n",
            "   macro avg       0.50      0.36      0.32      1093\n",
            "weighted avg       0.56      0.62      0.51      1093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_bxOtr5M11p"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5igKbIhM11s"
      },
      "source": [
        "# params\n",
        "n_folds = 5\n",
        "ModelName = MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XKT5NWUM11y",
        "outputId": "6a3ab755-eb2a-461c-a05a-c1e6cb86e629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "test_y_all = []\n",
        "test_pred_y_all = []\n",
        "parameters = {'hidden_layer_sizes':((8,8),(16,8),(32,8),(64,8)),'max_iter':(500,),'batch_size':(16,32,64),\n",
        "              'solver':('adam',)}\n",
        "model = ModelName()\n",
        "for fold in range(n_folds):\n",
        "  print('fold',fold)\n",
        "  ######## Hyperparameter search#########################\n",
        "  ps = PredefinedSplit([0 for _ in data_dict[fold]['val_X']]+[-1 for _ in data_dict[fold]['train_X']])\n",
        "  clf = GridSearchCV(model, parameters, cv=ps, scoring='neg_log_loss', refit=False)\n",
        "  clf.fit(data_dict[fold]['val_X'].tolist()+data_dict[fold]['train_X'].tolist(), \n",
        "          data_dict[fold]['val_y'].tolist()+data_dict[fold]['train_y'].tolist())\n",
        "  print(clf.best_params_)\n",
        "  ######### Fit-predict with best params#################\n",
        "  model = ModelName(**clf.best_params_)\n",
        "  model.fit(data_dict[fold]['train_X'],data_dict[fold]['train_y'])\n",
        "  test_y_all.extend(data_dict[fold]['test_y'].tolist())\n",
        "  test_pred_y_all.extend(model.predict(data_dict[fold]['test_X']))\n",
        "print(classification_report(test_y_all, test_pred_y_all))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "{'batch_size': 32, 'hidden_layer_sizes': (16, 8), 'max_iter': 500, 'solver': 'adam'}\n",
            "fold 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64, 'hidden_layer_sizes': (64, 8), 'max_iter': 500, 'solver': 'adam'}\n",
            "fold 2\n",
            "{'batch_size': 32, 'hidden_layer_sizes': (64, 8), 'max_iter': 500, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 32, 'hidden_layer_sizes': (32, 8), 'max_iter': 500, 'solver': 'adam'}\n",
            "fold 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 16, 'hidden_layer_sizes': (8, 8), 'max_iter': 500, 'solver': 'adam'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.35      0.34       187\n",
            "           1       0.71      0.72      0.71       668\n",
            "           2       0.36      0.32      0.34       238\n",
            "\n",
            "    accuracy                           0.57      1093\n",
            "   macro avg       0.46      0.46      0.46      1093\n",
            "weighted avg       0.57      0.57      0.57      1093\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYyslq7UTtL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}